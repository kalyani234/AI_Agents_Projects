{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzCRHpmEFuTN81ExsEwVUO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalyani234/AI_Agents_Projects/blob/CrewAI/CrewAI_Event_Management_Multi_Agent_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Project Description\n",
        "\n",
        " ü§ñ Event Management Multi-Agent Framework is an AI-powered system that uses three specialized agents‚ÄîVenue, Logistics, and Marketing‚Äîto plan and manage events.\n",
        "\n",
        "- The Venue Agent finds suitable venues\n",
        "- The Logistics Agent confirms bookings and arranges essentials\n",
        "- the Marketing Agent promotes the event.\n",
        "\n",
        "Together, they automate event planning from venue selection to final outreach."
      ],
      "metadata": {
        "id": "N8b3alGJlm4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "azjS0IxyLkpZ",
        "outputId": "e7f41378-f3f3-4226-b00d-27437179f7f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai==0.28.8\n",
            "  Downloading crewai-0.28.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting crewai_tools==0.1.6\n",
            "  Downloading crewai_tools-0.1.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langchain_community==0.0.29\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting appdirs<2.0.0,>=1.4.4 (from crewai==0.28.8)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from crewai==0.28.8) (8.3.1)\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.128-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting instructor<0.6.0,>=0.5.2 (from crewai==0.28.8)\n",
            "  Downloading instructor-0.5.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting openai<2.0.0,>=1.13.3 (from crewai==0.28.8)\n",
            "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from crewai==0.28.8) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from crewai==0.28.8) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from crewai==0.28.8) (1.37.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from crewai==0.28.8) (2.12.3)\n",
            "Collecting python-dotenv==1.0.0 (from crewai==0.28.8)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting regex<2024.0.0,>=2023.12.25 (from crewai==0.28.8)\n",
            "  Downloading regex-2023.12.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from crewai_tools==0.1.6) (4.13.5)\n",
            "Collecting chromadb<0.5.0,>=0.4.22 (from crewai_tools==0.1.6)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting lancedb<0.6.0,>=0.5.4 (from crewai_tools==0.1.6)\n",
            "  Downloading lancedb-0.5.7-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pyright<2.0.0,>=1.1.350 (from crewai_tools==0.1.6)\n",
            "  Downloading pyright-1.1.407-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pytest<9.0.0,>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from crewai_tools==0.1.6) (8.4.2)\n",
            "Collecting pytube<16.0.0,>=15.0.0 (from crewai_tools==0.1.6)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from crewai_tools==0.1.6) (2.32.4)\n",
            "Collecting selenium<5.0.0,>=4.18.1 (from crewai_tools==0.1.6)\n",
            "  Downloading selenium-4.38.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.0.29) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.0.29) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.0.29) (3.13.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.0.29)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain_community==0.0.29)\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community==0.0.29)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1 (from langchain_community==0.0.29)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0 (from langchain_community==0.0.29)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.22.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (4.15.0)\n",
            "Collecting build>=1.0.3 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading chroma-hnswlib-0.7.3.tar.gz (31 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.12/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.118.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.38.0)\n",
            "Collecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading posthog-7.0.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading pulsar_client-3.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.11.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /usr/local/lib/python3.12/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.17.2)\n",
            "INFO: pip is looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.127-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.126-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.125-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.124-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading cohere-5.20.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.12/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.128.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.123-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.122-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.121-py3-none-any.whl.metadata (9.3 kB)\n",
            "INFO: pip is still looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading embedchain-0.1.120-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.119-py3-none-any.whl.metadata (9.1 kB)\n",
            "  Downloading embedchain-0.1.118-py3-none-any.whl.metadata (9.1 kB)\n",
            "  Downloading embedchain-0.1.117-py3-none-any.whl.metadata (9.1 kB)\n",
            "  Downloading embedchain-0.1.116-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting clarifai<11.0.0,>=10.0.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai-10.11.1-py3-none-any.whl.metadata (22 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.115-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading embedchain-0.1.114-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading embedchain-0.1.113-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_cohere-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.12/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (13.9.4)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading schema-0.7.8-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading tiktoken-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "\u001b[33mWARNING: embedchain 0.1.128 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.128 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[33mWARNING: embedchain 0.1.127 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.127 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is still looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting PyGithub<2.0.0,>=1.59.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading PyGithub-1.59.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: gitpython<4.0.0,>=3.1.38 in /usr/local/lib/python3.12/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (3.1.45)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting youtube-transcript-api<0.7.0,>=0.6.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting yt_dlp<2024.0.0,>=2023.11.14 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl.metadata (160 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m160.7/160.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai==0.28.8)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.12/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (2.1.0)\n",
            "Collecting pylance==0.9.18 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting ratelimiter~=1.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting retry>=0.9.2 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting semver>=3.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (6.2.2)\n",
            "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.12/dist-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (18.1.0)\n",
            "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
            "  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (1.33)\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.28.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai==0.28.8) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.4.2)\n",
            "Collecting nodeenv>=1.6.0 (from pyright<2.0.0,>=1.1.350->crewai_tools==0.1.6)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2025.11.12)\n",
            "Collecting trio<1.0,>=0.31.0 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket<1.0,>=0.12.2 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.9.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.29) (3.2.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.3.10)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting clarifai-grpc>=10.11.2 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai_grpc-11.10.10-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting clarifai-protocol>=0.0.14 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai_protocol-0.0.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "Collecting tritonclient>=2.34.0 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading tritonclient-2.63.0-py3-none-manylinux1_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: Pillow>=9.5.0 in /usr/local/lib/python3.12/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (11.3.0)\n",
            "Collecting inquirerpy==0.3.4 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.9.0)\n",
            "Collecting fsspec==2024.6.1 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting click<9.0.0,>=8.1.7 (from crewai==0.28.8)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting contextlib2>=0.5.5 (from schema<0.8.0,>=0.7.5->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.52)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (4.0.12)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.28.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.43.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.26.1)\n",
            "Requirement already satisfied: google-cloud-storage<4.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.6.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.38.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.15.0)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.1.2)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.37.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.52.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai==0.28.8) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.9.0.post0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.0.0)\n",
            "INFO: pip is looking at multiple versions of kubernetes to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.3.1)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "INFO: pip is looking at multiple versions of langchain-cohere to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_cohere-0.1.8-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.7-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.5-py3-none-any.whl.metadata (6.4 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_openai-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.14.0)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-grpc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.59b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.58b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.58b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.58b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.58b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting opentelemetry-util-http==0.58b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_util_http-0.58b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.58b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.58b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading asgiref-3.11.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting deprecated (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2.10.1)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading pynacl-1.6.1-cp38-abi3-manylinux_2_34_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.12/dist-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.0.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.36.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (2.4.0)\n",
            "Collecting outcome (from trio<1.0,>=0.31.0->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading wsproto-1.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.7.1)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (15.0.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api<0.7.0,>=0.6.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (0.7.1)\n",
            "Collecting mutagen (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.12/dist-packages (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (3.23.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.2.0)\n",
            "INFO: pip is looking at multiple versions of clarifai-protocol to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting clarifai-protocol>=0.0.14 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai_protocol-0.0.33-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.32-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.31-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.30-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.29-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.28-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.27-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "INFO: pip is still looking at multiple versions of clarifai-protocol to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading clarifai_protocol-0.0.26-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.25-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.24-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.23-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.22-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading clarifai_protocol-0.0.21-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.20-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.19-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (5.0.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.8.0)\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigquery to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading google_cloud_bigquery-3.37.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "  Downloading google_cloud_bigquery-3.36.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "  Downloading google_cloud_bigquery-3.35.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "  Downloading google_cloud_bigquery-3.35.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "  Downloading google_cloud_bigquery-3.34.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "  Downloading google_cloud_bigquery-3.33.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "  Downloading google_cloud_bigquery-3.31.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "INFO: pip is still looking at multiple versions of google-cloud-bigquery to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading google_cloud_bigquery-3.30.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.14.3)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (43.0.3)\n",
            "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2.0.0)\n",
            "Collecting perf-analyzer (from tritonclient>=2.34.0->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading perf_analyzer-0.1.0-py3-none-any.whl.metadata (135 bytes)\n",
            "Collecting python-rapidjson>=0.9.1 (from tritonclient>=2.34.0->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading python_rapidjson-1.22-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (24 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2.23)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.2.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.6.1)\n",
            "Downloading crewai-0.28.8-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai_tools-0.1.6-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading embedchain-0.1.113-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
            "Downloading lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.407-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2023.12.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (789 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m789.1/789.1 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.38.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading clarifai-10.11.1-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Downloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.1.5-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.58b0-py3-none-any.whl (13 kB)\n",
            "Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl (33 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.58b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.58b0-py3-none-any.whl (7.7 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pulsar_client-3.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
            "Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading tiktoken-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.32.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m512.0/512.0 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading clarifai_grpc-11.10.10-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m306.5/306.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clarifai_protocol-0.0.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (402 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m402.5/402.5 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.20.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading google_cloud_bigquery-3.30.0-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m247.9/247.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynacl-1.6.1-cp38-abi3-manylinux_2_34_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tritonclient-2.63.0-py3-none-manylinux1_x86_64.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.3.2-py3-none-any.whl (24 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.11.0-py3-none-any.whl (24 kB)\n",
            "Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Downloading python_rapidjson-1.22-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading perf_analyzer-0.1.0-py3-none-any.whl (2.3 kB)\n",
            "Building wheels for collected packages: chroma-hnswlib, pypika\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.3-cp312-cp312-linux_x86_64.whl size=2530623 sha256=76a0070bf2c46d4bc2027d41b46d12b8588b62584fc28d647a5f940df998535e\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/14/b5/68c4f2e056600c0348a94efba92dc975686ab72b714e0ca3d6\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=547820ddb2bc53e632cccf878162d11ebd06b77f5909f99061b56fcb2077ab89\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built chroma-hnswlib pypika\n",
            "Installing collected packages: ratelimiter, pypika, perf-analyzer, monotonic, durationpy, appdirs, wsproto, wrapt, uvloop, types-requests, tenacity, semver, regex, pytube, python-rapidjson, python-dotenv, pysbd, pyproject_hooks, pypdf, py, pulsar-client, pfzy, packaging, outcome, opentelemetry-util-http, numpy, nodeenv, mypy-extensions, mutagen, mmh3, humanfriendly, httpx-sse, httptools, fsspec, fastavro, docstring-parser, contextlib2, click, bcrypt, backoff, asgiref, yt_dlp, youtube-transcript-api, watchfiles, typing-inspect, typer, tritonclient, trio, tiktoken, schema, retry, pyright, pynacl, pylance, posthog, marshmallow, inquirerpy, gptcache, deprecated, coloredlogs, clarifai-grpc, chroma-hnswlib, build, trio-websocket, openai, onnxruntime, langsmith, lancedb, kubernetes, dataclasses-json, selenium, PyGithub, opentelemetry-instrumentation, langchain-core, instructor, cohere, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, langchain_community, langchain-cohere, google-cloud-bigquery, opentelemetry-instrumentation-fastapi, langchain, chromadb, clarifai-protocol, clarifai, embedchain, crewai_tools, crewai\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.1\n",
            "    Uninstalling wrapt-2.0.1:\n",
            "      Successfully uninstalled wrapt-2.0.1\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.11.3\n",
            "    Uninstalling regex-2025.11.3:\n",
            "      Successfully uninstalled regex-2025.11.3\n",
            "  Attempting uninstall: python-dotenv\n",
            "    Found existing installation: python-dotenv 1.2.1\n",
            "    Uninstalling python-dotenv-1.2.1:\n",
            "      Successfully uninstalled python-dotenv-1.2.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: httpx-sse\n",
            "    Found existing installation: httpx-sse 0.4.3\n",
            "    Uninstalling httpx-sse-0.4.3:\n",
            "      Successfully uninstalled httpx-sse-0.4.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: docstring-parser\n",
            "    Found existing installation: docstring_parser 0.17.0\n",
            "    Uninstalling docstring_parser-0.17.0:\n",
            "      Successfully uninstalled docstring_parser-0.17.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.20.0\n",
            "    Uninstalling typer-0.20.0:\n",
            "      Successfully uninstalled typer-0.20.0\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.12.0\n",
            "    Uninstalling tiktoken-0.12.0:\n",
            "      Successfully uninstalled tiktoken-0.12.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.8.1\n",
            "    Uninstalling openai-2.8.1:\n",
            "      Successfully uninstalled openai-2.8.1\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.47\n",
            "    Uninstalling langsmith-0.4.47:\n",
            "      Successfully uninstalled langsmith-0.4.47\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.1.0\n",
            "    Uninstalling langchain-core-1.1.0:\n",
            "      Successfully uninstalled langchain-core-1.1.0\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 3.38.0\n",
            "    Uninstalling google-cloud-bigquery-3.38.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-3.38.0\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.1.0\n",
            "    Uninstalling langchain-1.1.0:\n",
            "      Successfully uninstalled langchain-1.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph-checkpoint 3.0.1 requires langchain-core>=0.2.38, but you have langchain-core 0.1.53 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "xarray 2025.11.0 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "gradio 5.50.0 requires typer<1.0,>=0.12, but you have typer 0.9.4 which is incompatible.\n",
            "bigframes 2.29.1 requires google-cloud-bigquery[bqstorage,pandas]>=3.36.0, but you have google-cloud-bigquery 3.30.0 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "db-dtypes 1.4.4 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
            "google-adk 1.19.0 requires click<9.0.0,>=8.1.8, but you have click 8.1.7 which is incompatible.\n",
            "google-adk 1.19.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyGithub-1.59.1 appdirs-1.4.4 asgiref-3.11.0 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chroma-hnswlib-0.7.3 chromadb-0.4.24 clarifai-10.11.1 clarifai-grpc-11.10.10 clarifai-protocol-0.0.14 click-8.1.7 cohere-5.20.0 coloredlogs-15.0.1 contextlib2-21.6.0 crewai-0.28.8 crewai_tools-0.1.6 dataclasses-json-0.6.7 deprecated-1.3.1 docstring-parser-0.15 durationpy-0.10 embedchain-0.1.113 fastavro-1.12.1 fsspec-2024.6.1 google-cloud-bigquery-3.30.0 gptcache-0.1.44 httptools-0.7.1 httpx-sse-0.4.0 humanfriendly-10.0 inquirerpy-0.3.4 instructor-0.5.2 kubernetes-33.1.0 lancedb-0.5.7 langchain-0.1.13 langchain-cohere-0.1.5 langchain-core-0.1.53 langchain-openai-0.1.7 langchain-text-splitters-0.0.2 langchain_community-0.0.29 langsmith-0.1.147 marshmallow-3.26.1 mmh3-5.2.0 monotonic-1.6 mutagen-1.47.0 mypy-extensions-1.1.0 nodeenv-1.9.1 numpy-1.26.4 onnxruntime-1.23.2 openai-1.109.1 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-instrumentation-0.58b0 opentelemetry-instrumentation-asgi-0.58b0 opentelemetry-instrumentation-fastapi-0.58b0 opentelemetry-util-http-0.58b0 outcome-1.3.0.post0 packaging-23.2 perf-analyzer-0.1.0 pfzy-0.3.4 posthog-3.25.0 pulsar-client-3.8.0 py-1.11.0 pylance-0.9.18 pynacl-1.6.1 pypdf-4.3.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.407 pysbd-0.3.4 python-dotenv-1.0.0 python-rapidjson-1.22 pytube-15.0.0 ratelimiter-1.2.0.post0 regex-2023.12.25 retry-0.9.2 schema-0.7.5 selenium-4.38.0 semver-3.0.4 tenacity-8.5.0 tiktoken-0.7.0 trio-0.32.0 trio-websocket-0.12.2 tritonclient-2.63.0 typer-0.9.4 types-requests-2.32.4.20250913 typing-inspect-0.9.0 uvloop-0.22.1 watchfiles-1.1.1 wrapt-1.17.3 wsproto-1.3.2 youtube-transcript-api-0.6.3 yt_dlp-2023.12.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy",
                  "packaging"
                ]
              },
              "id": "1ff1881b5e644cb0afb7b26dab6ff2d7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-Wey5fjBvq8I"
      },
      "outputs": [],
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"open_api\")\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get(\"serpi_api\")\n",
        "\n",
        "# required by CrewAI v0.28\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = \"gpt-4o-mini\"\n"
      ],
      "metadata": {
        "id": "9HD4pIuSw62Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Crew, Task"
      ],
      "metadata": {
        "id": "c3dLvgM7MJIZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CrewAI Tools"
      ],
      "metadata": {
        "id": "wjCfeBFFlZsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
        "\n",
        "# Initialize the tools\n",
        "search_tool = SerperDevTool()\n",
        "scrape_tool = ScrapeWebsiteTool()"
      ],
      "metadata": {
        "id": "CP3PqDpSMO74"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Agents"
      ],
      "metadata": {
        "id": "xgZNbx9bDb5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent 1: Venue Coordinator\n",
        "venue_coordinator = Agent(\n",
        "    role=\"Venue Coordinator\",\n",
        "    goal=\"Identify and book an appropriate venue \"\n",
        "    \"based on event requirements\",\n",
        "    tools=[search_tool, scrape_tool],\n",
        "    verbose=True,\n",
        "    backstory=(\n",
        "        \"With a keen sense of space and \"\n",
        "        \"understanding of event logistics, \"\n",
        "        \"you excel at finding and securing \"\n",
        "        \"the perfect venue that fits the event's theme, \"\n",
        "        \"size, and budget constraints.\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "57arjxQnz3ZM"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Agent 2: Logistics Manager\n",
        "logistics_manager = Agent(\n",
        "    role='Logistics Manager',\n",
        "    goal=(\n",
        "        \"Manage all logistics for the event\"\n",
        "        \"including catering and equipment\"\n",
        "    ),\n",
        "    tools=[search_tool, scrape_tool],\n",
        "    verbose=True,\n",
        "    backstory=(\n",
        "        \"Organized and detail-oriented, \"\n",
        "        \"you ensure that every logistical aspect of the event \"\n",
        "        \"from catering to equipment setup \"\n",
        "        \"is flawlessly executed to create a seamless experience.\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "MyNiNZ4Hz4df"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent 3: Marketing and Communications Agent\n",
        "marketing_communications_agent = Agent(\n",
        "    role=\"Marketing and Communications Agent\",\n",
        "    goal=\"Effectively market the event and \"\n",
        "         \"communicate with participants\",\n",
        "    tools=[search_tool, scrape_tool],\n",
        "    verbose=True,\n",
        "    backstory=(\n",
        "        \"Creative and communicative, \"\n",
        "        \"you craft compelling messages and \"\n",
        "        \"engage with potential attendees \"\n",
        "        \"to maximize event exposure and participation.\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "Nzv-F1APMbRa"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Venue Pydantic Object\n",
        "- Create a class VenueDetails using Pydantic BaseModel.\n",
        "- Agents will populate this object with information about different venues by creating different instances of it.\n",
        "\n"
      ],
      "metadata": {
        "id": "Z2n0bhKtVakK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "# Define a Pydantic model for venue details\n",
        "# (demonstrating Output as Pydantic)\n",
        "from typing import List\n",
        "\n",
        "class VenueDetails(BaseModel):\n",
        "    name: str\n",
        "    address: str\n",
        "    capacity: int\n",
        "    booking_status: str\n",
        "    event_schedule: str\n",
        "    transport_options: List[str]"
      ],
      "metadata": {
        "id": "5XTEUIyPVY8H"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Tasks\n",
        "- By using output_json, you can specify the structure of the output you want.\n",
        "- By using output_file, you can get your output in a file.\n",
        "- By setting human_input=True, the task will ask for human feedback (whether you like the results or not) before finalising it."
      ],
      "metadata": {
        "id": "CfI5nj2plOGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "venue_task = Task(\n",
        "    description=(\n",
        "        \"Find a venue in {event_city} that meets the criteria for \"\n",
        "        \"{event_topic}. The venue must support at least \"\n",
        "        \"{expected_participants} participants.\\n\\n\"\n",
        "        \"Include the event schedule: {event_schedule}.\\n\"\n",
        "        \"Also provide detailed transport options near the venue \"\n",
        "        \"such as train stations, airports, metro access, and parking availability.\\n\\n\"\n",
        "        \"You MUST populate all fields of the VenueDetails Pydantic model.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A complete VenueDetails Pydantic object including venue name, address, \"\n",
        "        \"capacity, booking_status, event_schedule, and transport_options.\"\n",
        "    ),\n",
        "    human_input=True,\n",
        "    output_json=VenueDetails,\n",
        "    output_file=\"venue_details.json\",\n",
        "    agent=venue_coordinator\n",
        ")\n"
      ],
      "metadata": {
        "id": "GzrqN0mCV5Zt"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistics_task = Task(\n",
        "    description=(\n",
        "        \"Review the selected venue details. The venue coordinator may mark \"\n",
        "        \"booking_status as 'To be confirmed'. It is your responsibility to \"\n",
        "        \"confirm venue booking availability for the date {tentative_date}.\\n\\n\"\n",
        "        \"After confirming, update the booking status to 'Confirmed'.\\n\"\n",
        "        \"Then coordinate catering and equipment for {expected_participants} \"\n",
        "        \"participants.\\n\"\n",
        "        \"Provide a detailed logistics confirmation summary including:\\n\"\n",
        "        \"- venue booking confirmation,\\n\"\n",
        "        \"- catering vendor,\\n\"\n",
        "        \"- equipment setup plan,\\n\"\n",
        "        \"- timing and delivery schedule.\\n\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A complete logistics confirmation including venue booking status, \"\n",
        "        \"catering arrangements, equipment setup, and scheduling details.\"\n",
        "    ),\n",
        "    human_input=True,\n",
        "    async_execution=True,\n",
        "    agent=logistics_manager\n",
        ")\n"
      ],
      "metadata": {
        "id": "KRU0mkp2WMzz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "marketing_task = Task(\n",
        "    description=(\n",
        "        \"Promote the event {event_topic} based on the confirmed venue details \"\n",
        "        \"and logistics plan. Ensure that you read the final venue information \"\n",
        "        \"including:\\n\"\n",
        "        \"- venue name,\\n\"\n",
        "        \"- address,\\n\"\n",
        "        \"- event schedule,\\n\"\n",
        "        \"- transport options,\\n\"\n",
        "        \"- confirmed booking status.\\n\\n\"\n",
        "        \"Create a promotional plan targeting at least {expected_participants} \"\n",
        "        \"potential attendees. Include social media strategy, email outreach, \"\n",
        "        \"and key messaging that highlights the venue and its accessibility.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A marketing report in markdown format including campaign strategy, \"\n",
        "        \"expected reach, platform-specific messaging, and how the venue \"\n",
        "        \"strengthens the event's appeal.\"\n",
        "    ),\n",
        "    async_execution=True,\n",
        "    output_file=\"marketing_report.md\",\n",
        "    agent=marketing_communications_agent\n",
        ")\n"
      ],
      "metadata": {
        "id": "_4FvFD4HWPnz"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Crew\n",
        "- Note: Since you set async_execution=True for logistics_task and marketing_task tasks\n",
        "- Now the order for them does not matter in the tasks list."
      ],
      "metadata": {
        "id": "Ah0smZdRWqll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the crew with agents and tasks\n",
        "event_management_crew = Crew(\n",
        "    agents=[venue_coordinator,\n",
        "            logistics_manager,\n",
        "            marketing_communications_agent],\n",
        "\n",
        "    tasks=[venue_task,\n",
        "           logistics_task,\n",
        "           marketing_task],\n",
        "\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMaBdU_xWoSQ",
        "outputId": "7c90cd34-7651-4f3c-ee0a-e85b8bbbb2e1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the Crew\n",
        "Set the inputs for the execution of the crew.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uvttffJTXGpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event_details = {\n",
        "    'event_topic': \"Global AI Leaders Summit 2025 in UK\",\n",
        "    'event_description': \"A gathering of tech innovators \"\n",
        "                         \"and industry leaders \"\n",
        "                         \"to explore future Data and AI technologies.\",\n",
        "    'event_city': \"London\",\n",
        "    'tentative_date': \"2025-12-15\",\n",
        "    'expected_participants': 1500,\n",
        "    'budget': 1200,\n",
        "    'event_schedule' : '9am - 5pm',\n",
        "    'venue_type': \"Conference Hall\"\n",
        "}"
      ],
      "metadata": {
        "id": "7WEXSZMbXQp-"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = event_management_crew.kickoff(inputs=event_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzVNM2BJX9CP",
        "outputId": "6362d454-3a3a-4745-815f-9cd4f657b927"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Venue Coordinator\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Find a venue in London that meets the criteria for Global AI Leaders Summit 2025 in UK. The venue must support at least 1500 participants.\n",
            "\n",
            "Include the event schedule: 9am - 5pm.\n",
            "Also provide detailed transport options near the venue such as train stations, airports, metro access, and parking availability.\n",
            "\n",
            "You MUST populate all fields of the VenueDetails Pydantic model.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find a suitable venue in London for the Global AI Leaders Summit 2025, which requires a capacity of at least 1500 participants. Additionally, I need to gather information about transport options near the venue, including train stations, airports, metro access, and parking availability. \n",
            "\n",
            "Action: Search the internet  \n",
            "Action Input: {\"search_query\": \"venues in London for 1500 participants Global AI Leaders Summit 2025\"}  \n",
            "\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: The AI Summit London\n",
            "Link: https://london.theaisummit.com/\n",
            "Snippet: Check out The Networking Caf√©, Start-up & Investor Village, VisionAIres Programme (VIP only), Demo Agenda, The AI Trail, The AIconics Awards, Masterclass & ...\n",
            "---\n",
            "Title: The AI Summit London 20255 Attendee List\n",
            "Link: https://vendelux.com/insights/the-ai-summit-london-2025-attendee-list/\n",
            "Snippet: Get The AI Summit London 2025 attendee list. 4500+ AI leaders, enterprise buyers, and data innovators shaping AI-driven transformation.\n",
            "---\n",
            "Title: Attendee Guide | The AI Summit London\n",
            "Link: https://london.theaisummit.com/whats-on/attendee-guide/\n",
            "Snippet: The AI Summit London 2025 will take place at Tobacco Dock. ... The AI Summit After Party ‚Äì a chance to connect with industry leaders and key players at the uber- ...\n",
            "---\n",
            "Title: Full Schedule, Location & Tickets - AI Conference UK 2025\n",
            "Link: https://aiconferences.ai/ai-conference-uk/\n",
            "Snippet: Unveiling AI Conference UK 2025. Full agenda, exciting London location, and ticket registration information inside.\n",
            "---\n",
            "Title: World's Top 5 AI Conferences in 2025 To Watch Out For\n",
            "Link: https://analyticsindiamag.com/ai-trends/worlds-top-5-ai-conferences-in-2025-to-watch-out-for/\n",
            "Snippet: As the headline AI event of London Tech Week, The AI Summit London unites the most innovative technologists and business leaders in the UK and ...\n",
            "---\n",
            "Title: AI Conference 2025\n",
            "Link: https://gailsummit.com/\n",
            "Snippet: GAILS - 2025. GLOBAL AI LEADERS SUMMIT. @. 21st AUG 2025 - IIT MADRAS (IC&SR Auditorium) Theme: Empowering Academia & Industry for the ...\n",
            "---\n",
            "Title: Box Summit London 2025: Content, AI, and the Enterprise\n",
            "Link: https://www.techuk.org/what-we-deliver/events/box-summit-london-2025-ai.html\n",
            "Snippet: This practical, education‚Äëled day in central London focuses on the frameworks, governance, and real‚Äëworld workflows needed to make AI useful across the ...\n",
            "---\n",
            "Title: Tech & AI LIVE London 2025\n",
            "Link: https://technologymagazine.com/events/tech-and-ai-live/tech-and-ai-live-london-2025\n",
            "Snippet: Join us live at 155 Bishopsgate, London, on 14-15 May 2025 for Tech & AI LIVE London, the premier event for C/V/D-level technology, AI and cyber executives.\n",
            "---\n",
            "Title: Conference Venue\n",
            "Link: https://aiconference.london/venue\n",
            "Snippet: Join us at The Great Hall in the Kensington Conference and Events Centre for AI World Congress 2025. Located in the heart of London, this prestigious venue ...\n",
            "---\n",
            "Title: Top AI Conferences in 2025 and 2026: In-Person ...\n",
            "Link: https://explodingtopics.com/blog/ai-conferences\n",
            "Snippet: Discover the top AI conferences in 2025 and 2026. Explore global events, virtual options, and networking opportunities to stay ahead in AI.\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: \n",
            "I found a relevant venue mentioned in the search results - Tobacco Dock, which is hosting the AI Summit London 2025. I need to gather more information about this venue, including its capacity, booking status, event schedule, and transport options.\n",
            "\n",
            "Action: Read website content  \n",
            "Action Input: {\"website_url\": \"https://london.theaisummit.com/\"}  \n",
            "\u001b[0m\u001b[95m \n",
            "\n",
            "The AI Summit LondonThis site is part of Informa PLCInforma PLCAbout UsInvestor relationsTalentThis site is operated by a business or businesses owned by Informa PLC and all copyright resides with them. Informa PLC's registered office is 5 Howick Place, London SW1P 1WG. Registered in England and Wales. Number 3099067.What‚Äôs OnOverviewWho AttendsExhibitor ListAIconics AwardsAgendaConference AgendaPremium StagesHeadliners AgendaFringe EventsVIP ExperienceExpo ExperienceSpeakersConference LineupSubmit a SpeakerSponsorshipSponsorshipSuccess StoriesSponsors & PartnersMedia & Community PartnersAboutAbout the SummitThe SeriesFAQsPress & MediaAmbassador ChapterTestimonialsPrevious Event HighlightsContact UsPasses & PricingRegister InterestWhat‚Äôs OnAgendaSpeakersSponsorshipAboutPasses & PricingRegister Interest10-11 June 2026 | Tobacco Dock, LondonThe AI Summit LondonFrom AI Breakthroughs to Bottom‚ÄëLine ImpactHeading into our 10th year, the Summit delivers cutting-edge insights, high‚Äëvalue connections and strategies to accelerate AI‚Äëdriven growth ‚Äì whether you're streamlining operations or reshaping entire industries.As the headline AI event of London Tech Week, this is where commercial AI comes to life.Register InterestPurchase On-Demand100+ SPONSORS & EXHIBITORSIMMERSIVE AI EXPERIENCESVIP PROGRAMMECUTTING-EDGE AI DEMOS8 STAGES OF CONTENT4500+ ATTENDEES300+ SPEAKERSThanks to Everyone Who Joined Us in 2025Stellar Conference SpeakersOur¬†300+ speaker line-up is absolutely unmatched, including the Heads of Policy & Public Engagement, Vice Presidents, Chief Privacy & Data Responsibility Officers, Directors for Technology and Research Investments and more!World-Leading ProgrammeHear world-class curated content across six incredible stages from a line-up of star speakers. Learn about the latest trends, ground-breaking research, and innovative applications that are transforming industries worldwide.Access Incredible FeaturesCheck out The Networking Caf√©, Start-up & Investor Village, VisionAIres Programme (VIP only), Demo Agenda, The AI Trail, The AIconics Awards, Masterclass & Workshop Programme, plus some surprises across an action-packed two days.Explore the AI Summit ExpoSee 100+ leading tech companies showcasing their latest AI solutions and products. Discover the tools and innovations that can propel your business forward.Networking & PartiesConnect with 4,500+ attendees (get a hint as to who). There's plenty of opportunities to meet and mingle with your peers at The Networking Caf√©, across The Expo Floor, walking The AI Trail and at our official After-Party.Our Ambassador ChapterMeet the Expert Advisers Driving the Event's AgendaAt the heart of The AI Summit London lies our distinguished Ambassador Chapter. This esteemed group ‚Äì featuring some of the brightest minds from Mastercard, HPE, BP, Unilever, Google DeepMind, EY, IBM, AstraZeneca, and beyond ‚Äì are not just advisors; they are the architects of the Summit's cutting-edge event agenda, ensuring that every moment you spend with us is an investment in your future.Uthman AliGlobal Responsible AI OfficerBP United KingdomMatt Armstrong-BarnesGlobal AI Practice DirectorServitaZo√´ BrammerPublic Policy ManagerGoogle DeepMindCatriona CampbellUK&I Client AI Strategy LeaderEYMatthew CandyGlobal Managing Partner, Generative AIIBMDonatien Chedom FotsoDirector, Artificial IntelligenceEPAM SystemsGhida Ibrahim, PhDVP, Product & DataSector Alarm GroupAhmed MenshawyVice President, AI EngineeringMastercardAlberto PradoGlobal Head, R&D Digital & PartnershipsUnileverMargi ShethSenior Director, Data & AI PolicyAstraZenecaLiz WilliamsChief Executive OfficerFutureDotNowBy attending The AI Summit London, you're not just participating in a conference, you're tapping into the collective wisdom of AI's most influential thought leaders. Our Ambassador Chapter guarantees that the insights you gain will be transformative, actionable and light-years ahead of the curve.Get to Know ThemExplore. Innovate. Advance.The ConferenceFuture-proof your skills! Gain the knowledge you need to thrive in an increasingly AI-powered world.Explore the AgendaThe PeopleRub shoulders with the industry's top players ‚Äì everyone you need to know is coming.See Who AttendsThe ExhibitionGet connected at our interactive exhibition ‚Äì meet big-name brands, discover demos, and uncover solutions to your toughest tech challenges.Learn MoreI was literally blown away by the content, interest and breadth of information. Not to mention the size of the event.Gordan MilinkoviƒáPartner and FounderSpike Reply UKIt was great to see the demos and hearing from different companies and industries on their experience so far with AI, the importance of regulations, principles and standards along with communication, trust and connection.Anna DillonSenior Project ManagereasyJetThe London AI Summit was a breath of fresh air, sparking inspiration, opening up a myriad of new ideas and potential collaborations. The pace of AI innovation is scary.John AdeojoDirector & Chief Data ScientistData-Centric SolutionsI really enjoyed the round table discussion and learned a lot from my colleagues' insights. The AI Summit second day was an eye opener.James BellHead of Data Enablement & OperationsNews CorpThe AISummitLondon10-11 June 2026Tobacco Dock, LondonThank You to All Our Sponsors & PartnersSee All Sponsors & PartnersThe AI Summit LondonWhere commercial AI comes to life10-11 June 2026Tobacco DockTobacco Quay, Wapping LaneLondon, E1W 2SFQuick LinksHomeContact UsThe AI Summit SingaporeThe AI Summit at Black Hat USAThe AI Summit Cape TownThe AI Summit New YorkFollow Us#TheAISummit\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: \n",
            "I gathered information about the AI Summit London which will take place at Tobacco Dock. I need to find specific details about the venue including its capacity, booking status, event schedule, and transport options.\n",
            "\n",
            "Action: Search the internet  \n",
            "Action Input: {\"search_query\": \"Tobacco Dock London venue capacity and transport options\"}  \n",
            "\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: Consumer Trade Show Venues in London\n",
            "Link: https://www.tobaccodocklondon.com/consumer-events/\n",
            "Snippet: Our unique consumer show spaces offer ideal and distinctive settings for a range of event types and sizes, with a venue capacity of 10,000. Our mixture of ...\n",
            "---\n",
            "Title: Tobacco Dock\n",
            "Link: https://www.cvent.com/venues/london/special-event-venue/tobacco-dock/venue-a8837bb3-4e98-44d2-b98b-cfe2f80e888c\n",
            "Snippet: Tobacco Dock is a multi-award-winning experiential venue in London for 50 - 7,000 delegates. - 57 versatile event spaces with capacities ranging from 6 - 1,500.\n",
            "---\n",
            "Title: Small conferences\n",
            "Link: https://www.tobaccodocklondon.com/small-conferences/\n",
            "Snippet: We offer self-contained conference spaces offering everything you need for an impressive and impactful conference for up to 250 attendees.\n",
            "---\n",
            "Title: Tobacco Dock - London Event Venues\n",
            "Link: https://hirespace.com/Venues/London/2366/Tobacco-Dock\n",
            "Snippet: Ranging in capacity from 60-250 pax, they are perfect for breakout sessions and workshop spaces within a wider conference. Benefitting from impressive lighting ...\n",
            "---\n",
            "Title: Tobacco Dock - London, United Kingdom\n",
            "Link: https://citydays.com/places/tobacco-dock/\n",
            "Snippet: With a maximum capacity of 10,000 guests, it's perfectly suited for business meetings, multi-day conferences, intimate product launches, or even lavish parties.\n",
            "---\n",
            "Title: Tobacco Dock Venue Hire London\n",
            "Link: https://venues.london/venue/tobacco-dock-venue-hire/\n",
            "Snippet: Capacity ¬∑ Standing. 1000 guests ¬∑ Seated Meal. 500 guests ¬∑ Conference. 700 guests ...\n",
            "---\n",
            "Title: Tobacco Dock: Unique Event Venue Space in London\n",
            "Link: https://www.tobaccodocklondon.com/\n",
            "Snippet: Tobacco Dock is a premier event venue space in a prime London location. Our large, unique venue can be adapted to a range of formats, impressing our ...\n",
            "---\n",
            "Title: Tobacco Dock - Find Venues in London & Inspiring event ideas\n",
            "Link: https://www.londonlaunch.com/venues/tobacco-dock/\n",
            "Snippet: Encompassing 16,000 sqm and 57 different event spaces, Tobacco Dock can accommodate up to 10,000 guests. From conferences, product launches and exhibitions to ...\n",
            "---\n",
            "Title: The Tobacco Dock | Conference Venue\n",
            "Link: https://thecollectionevents.com/venues/tobacco-dock/conferences/\n",
            "Snippet: There are 57 different spaces available across this vast venue (16,000m¬≤) ranging from huge conference spaces to modern meeting rooms. The Great Gallery is one ...\n",
            "---\n",
            "Title: Churchill - Tobacco Dock - Event Venue Hire\n",
            "Link: https://www.tagvenue.com/rooms/london/97025/tobacco-dock/churchill\n",
            "Snippet: Book Churchill at Tobacco Dock online. Prices from ¬£110, capacity up to 45 guests. Browse photos and read reviews from customers who booked Churchill for ...\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: \n",
            "I have found relevant information about Tobacco Dock, a venue that can accommodate up to 10,000 guests. Now, I need to gather more specific details about transport options available near the venue, including train stations, airports, metro access, and parking facilities.\n",
            "\n",
            "Action: Search the internet  \n",
            "Action Input: {\"search_query\": \"transport options near Tobacco Dock London train stations airports metro access parking\"}  \n",
            "\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: How to get to Tobacco Dock from 5 nearby airports\n",
            "Link: https://www.rome2rio.com/s/Nearby-Airports/Tobacco-Dock\n",
            "Snippet: However, there are better options for getting to Tobacco Dock. Elizabeth Line (TfL) operates a train from Heathrow Terminals 2 & 3 to Whitechapel Station ...\n",
            "---\n",
            "Title: Tobacco Dock to London - 4 ways to travel via train, bus ...\n",
            "Link: https://www.rome2rio.com/s/Tobacco-Dock/London\n",
            "Snippet: There are 4 ways to get from Tobacco Dock to London by train, bus, taxi, or foot ; Train ¬∑ Take the train from Shadwell DLR to Bank DLR Station Dlr ; Bus. Take the ...\n",
            "---\n",
            "Title: How to Get to Tobacco Dock in Wapping by Train, Bus, ...\n",
            "Link: https://moovitapp.com/index/en-gb/public_transportation-Tobacco_Dock-London_and_South_East-site_6763782-2122\n",
            "Snippet: Directions to Tobacco Dock (Wapping) with public transport. The following transport lines have routes that pass near Tobacco Dock. Bus: 100, D3, N551.\n",
            "---\n",
            "Title: THE BEST 10 PARKING near TOBACCO DOCK CAR ...\n",
            "Link: https://m.yelp.com/search?cflt=parking&find_loc=Tobacco+Dock+Car+Park%2C+London+E1W+2SF\n",
            "Snippet: Best Parking in London - Last Updated November 2025 - Tower Bridge Parking, Minories Car Park, Sky Garden, Houndsditch Multi Storey, M T Autos, ...\n",
            "---\n",
            "Title: Getting to Central London\n",
            "Link: https://www.heathrow.com/transport-and-directions/getting-to-central-london\n",
            "Snippet: Compare travel options between Heathrow Airport and central London - train, taxi, bus, coach or London Underground.\n",
            "---\n",
            "Title: How to get to Tobacco Dock (Station) from 5 nearby airports\n",
            "Link: https://www.rome2rio.com/s/Nearby-Airports/Tobacco-Dock-Station\n",
            "Snippet: Elizabeth Line (TfL) operates a train from Heathrow Terminals 2 & 3 to Whitechapel Station every 20 minutes. Tickets cost ¬£16 - ¬£20 and the journey takes 41 min ...\n",
            "---\n",
            "Title: Train Travel and London Gatwick\n",
            "Link: https://www.gatwickairport.com/transport-options/train.html\n",
            "Snippet: Travel to over 120 train stations directly from London Gatwick, offering unrivalled connectivity into London and the South East.\n",
            "---\n",
            "Title: By rail or train\n",
            "Link: https://www.heathrow.com/transport-and-directions/by-rail-or-train\n",
            "Snippet: Trains to London Heathrow Airport (LHR). Compare Heathrow Express, TfL Rail and bus links to mainline rail stations.\n",
            "---\n",
            "Title: Everything you MUST know about London transport (full ...\n",
            "Link: https://www.youtube.com/watch?v=ZJyauWRD7Q4\n",
            "Snippet: I'm going to walk you through all of the public transport options we have here in London even the pointless ones so you can see all the ways.\n",
            "---\n",
            "Title: London City Airport DLR Station to Tobacco Dock\n",
            "Link: https://www.rome2rio.com/s/London-City-Airport-DLR-Station/Tobacco-Dock\n",
            "Snippet: There are 5 ways to get from London City Airport DLR Station to Tobacco Dock by train, bus, taxi, car, or towncar ¬∑ Train ¬∑ Line 474 bus, bus ¬∑ Taxi ¬∑ Drive 5.4 mi.\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: \n",
            "I now have enough information about Tobacco Dock, including its capacity and location. I need to summarize the transport options available near the venue, including train stations, airports, metro access, and parking facilities. \n",
            "\n",
            "Action: Read website content  \n",
            "Action Input: {\"website_url\": \"https://www.tobaccodocklondon.com/\"}  \n",
            "\u001b[0m\u001b[95m \n",
            "\n",
            "Unique Event Venue Space in London | Tobacco Dock\n",
            "Organise an event\n",
            "Organiser Overview\n",
            "Event Spaces\n",
            "Event Types\n",
            "Case Studies\n",
            "Sustainability & CSR\n",
            "Accessibility\n",
            "Service Partners\n",
            "Workspaces\n",
            "Christmas\n",
            "About\n",
            "Location\n",
            "COMMUNITY FUND\n",
            "Careers\n",
            "Blog\n",
            "Call us on 0207 680 4001\n",
            "or ENQUIRE NOW\n",
            "Organise an event\n",
            "Event Spaces\n",
            "Event Types\n",
            "Case Studies\n",
            "Sustainability & CSR\n",
            "Accessibility\n",
            "Service Partners\n",
            "What‚Äôs On\n",
            "Workspaces\n",
            "Christmas\n",
            "Contact\n",
            "About\n",
            "Location\n",
            "Careers\n",
            "COMMUNITY FUND\n",
            "Blog\n",
            "Choose extraordinary\n",
            "Tobacco Dock is London's most creative venue, working with our clients to deliver truly extraordinary live events, connecting people to exchange ideas, discover new products, enjoy great food, drinks and music, and do business. \n",
            "Start planning now\n",
            "Workspaces\n",
            "Grow your business within London's most exciting events venue. Tobacco Dock Workspaces offers co-working space, private offices and meeting rooms to suit every stage of your company's development.\n",
            "our workspaces\n",
            "what‚Äôs on\n",
            "We've an exciting calendar of events here at Tobacco Dock, from food festivals, to live music events, large conferences to awards dinners. Get your diary out and get clicking!\n",
            "upcoming events\n",
            "Sorry, this browser does not supported this video type \n",
            "Sweat, meat, gin, repeat - book today\n",
            "Meatopia, London Craft Beer Festival, Junipalooza, Festa, Perform X, Bike Shed... Every year we play host to some of the world's busiest and most exciting consumer trade events. Whether your show involves leotards or Kawasakis, chances are we have a space for you!\n",
            "Visitors\n",
            "2000000\n",
            "Events Held\n",
            "1500\n",
            "Find your event space\n",
            "View our case studies\n",
            "Exceptional team\n",
            "At Tobacco Dock, you don't just hire our spaces - you also get our award-winning team. We excel at creating ground-breaking events in our unique venue. Our aim is to make planning a world-class event as straightforward and enjoyable as possible. \n",
            "Talk to us\n",
            "How to find tobacco dock \n",
            "Tobacco Dock is located in the heart of East London‚Äôs thriving enterprise zone, within striking distance of Central London and straightforward to reach by public transport, lying between Wapping (Overground) and Shadwell (Overground and DLR) stations, as well as plenty of nearby bus stops (routes 100 and D3).\n",
            "Shadwell Station\n",
            "5¬†mins\n",
            "canary wharf dlr\n",
            "15¬†mins\n",
            "shoreditch overground\n",
            "2¬†stops\n",
            "wapping station\n",
            "6¬†mins\n",
            "bank dlr\n",
            "1¬†stop\n",
            "tower hill station\n",
            "15¬†mins\n",
            "where we are\n",
            "Our iconic gates\n",
            "Modern events in a historic setting\n",
            "Tobacco Dock was built in 1812 as a bustling hub for luxury commodities from the New World. Sensitively and ambitiously restored in 2012 Tobacco Dock has sealed its reputation as one of the coolest events spaces in the capital. The Grade 1 listed building is a masterpiece of industrial architecture and an icon of the East London landscape.\n",
            "Who We Are\n",
            "Have an Enquiry? \n",
            "Have an Enquiry?\n",
            "Enquiry TypeOrganise an EventWhat's on/GeneralWorkspacesLocal Resident Support\n",
            "Event TypeConferenceMeeting (up to 30pax)Exhibition/Trade ShowProduct LaunchAward DinnerParty or Drinks ReceptionConsumer ShowPrivate EventFilmingOther\n",
            "Start of event\n",
            "End of event\n",
            "For more information on how we process your personal data, please visit our Privacy Policy.\n",
            "Event Spaces\n",
            "Great GalleryLittle GalleryDock GalleryQuayside 1 and 2East MallQuayside BreakoutsNorth DockNorth VaultsSouth VaultsEast DockEast Dock Meeting SuiteSouth Dock Meeting SuiteDock St Bar \n",
            "Event Types\n",
            "SummitsConferencesProduct launchesConsumer ShowsReceptions and partiesChristmas PartiesAwards DinnersFashion Shows \n",
            "Navigation\n",
            "Organise an event\n",
            "What‚Äôs On\n",
            "Contact\n",
            "About\n",
            "Blog\n",
            "Workspaces\n",
            "Case Studies\n",
            "Service Partners\n",
            "Call us on 0207 680 4001\n",
            "or Enquire Now\n",
            "Call Us\n",
            "Enquire Now\n",
            "¬© 2025 Tobacco Dock Venue Ltd.\n",
            "Privacy Policy\n",
            "Terms & Conditions\n",
            "Site by Strafe\n",
            "\u001b[00m\n",
            "This is the agent final answer: ```json\n",
            "{\n",
            "  \"venue_name\": \"Tobacco Dock\",\n",
            "  \"address\": \"Tobacco Quay, Wapping Lane, London, E1W 2SF\",\n",
            "  \"capacity\": 10000,\n",
            "  \"booking_status\": \"Available for booking\",\n",
            "  \"event_schedule\": {\n",
            "    \"start_time\": \"09:00\",\n",
            "    \"end_time\": \"17:00\"\n",
            "  },\n",
            "  \"transport_options\": {\n",
            "    \"train_stations\": [\n",
            "      {\n",
            "        \"station_name\": \"Shadwell Station\",\n",
            "        \"distance\": \"5 mins walk\"\n",
            "      },\n",
            "      {\n",
            "        \"station_name\": \"Wapping Station\",\n",
            "        \"distance\": \"6 mins walk\"\n",
            "      }\n",
            "    ],\n",
            "    \"metro_access\": [\n",
            "      {\n",
            "        \"line\": \"DLR\",\n",
            "        \"stations\": [\"Tower Hill Station (15 mins)\", \"Bank DLR Station (1 stop)\"]\n",
            "      },\n",
            "      {\n",
            "        \"line\": \"Overground\",\n",
            "        \"stations\": [\"Canary Wharf DLR (15 mins)\", \"Shoreditch Overground (2 stops)\"]\n",
            "      }\n",
            "    ],\n",
            "    \"airports\": [\n",
            "      {\n",
            "        \"airport_name\": \"London City Airport\",\n",
            "        \"distance\": \"5.4 miles\"\n",
            "      },\n",
            "      {\n",
            "        \"airport_name\": \"Heathrow Airport\",\n",
            "        \"train_service\": \"Elizabeth Line to Whitechapel Station\"\n",
            "      }\n",
            "    ],\n",
            "    \"bus_routes\": [\n",
            "      {\n",
            "        \"route_number\": \"100\",\n",
            "        \"description\": \"Direct bus service to Tobacco Dock\"\n",
            "      },\n",
            "      {\n",
            "        \"route_number\": \"D3\",\n",
            "        \"description\": \"Direct bus service to Tobacco Dock\"\n",
            "      }\n",
            "    ],\n",
            "    \"parking_availability\": \"Nearby parking options available, including Tower Bridge Parking and Minories Car Park.\"\n",
            "  }\n",
            "}\n",
            "```\n",
            "Please provide a feedback: good\n",
            "\u001b[32;1m\u001b[1;3mThought: I have gathered comprehensive information about Tobacco Dock, including its capacity and transport options. I will now compile all the details into the VenueDetails Pydantic model format, which includes venue name, address, capacity, booking status, event schedule, and transport options. I need to double-check for any additional details or corrections to ensure the final answer is accurate.\n",
            "\n",
            "Final Answer: \n",
            "```json\n",
            "{\n",
            "  \"venue_name\": \"Tobacco Dock\",\n",
            "  \"address\": \"Tobacco Quay, Wapping Lane, London, E1W 2SF\",\n",
            "  \"capacity\": 10000,\n",
            "  \"booking_status\": \"Available for booking\",\n",
            "  \"event_schedule\": {\n",
            "    \"start_time\": \"09:00\",\n",
            "    \"end_time\": \"17:00\"\n",
            "  },\n",
            "  \"transport_options\": {\n",
            "    \"train_stations\": [\n",
            "      {\n",
            "        \"station_name\": \"Shadwell Station\",\n",
            "        \"distance\": \"5 mins walk\"\n",
            "      },\n",
            "      {\n",
            "        \"station_name\": \"Wapping Station\",\n",
            "        \"distance\": \"6 mins walk\"\n",
            "      }\n",
            "    ],\n",
            "    \"metro_access\": [\n",
            "      {\n",
            "        \"line\": \"DLR\",\n",
            "        \"stations\": [\"Tower Hill Station (15 mins)\", \"Bank DLR Station (1 stop)\"]\n",
            "      },\n",
            "      {\n",
            "        \"line\": \"Overground\",\n",
            "        \"stations\": [\"Canary Wharf DLR (15 mins)\", \"Shoreditch Overground (2 stops)\"]\n",
            "      }\n",
            "    ],\n",
            "    \"airports\": [\n",
            "      {\n",
            "        \"airport_name\": \"London City Airport\",\n",
            "        \"distance\": \"5.4 miles\"\n",
            "      },\n",
            "      {\n",
            "        \"airport_name\": \"Heathrow Airport\",\n",
            "        \"train_service\": \"Elizabeth Line to Whitechapel Station\"\n",
            "      }\n",
            "    ],\n",
            "    \"bus_routes\": [\n",
            "      {\n",
            "        \"route_number\": \"100\",\n",
            "        \"description\": \"Direct bus service to Tobacco Dock\"\n",
            "      },\n",
            "      {\n",
            "        \"route_number\": \"D3\",\n",
            "        \"description\": \"Direct bus service to Tobacco Dock\"\n",
            "      }\n",
            "    ],\n",
            "    \"parking_availability\": \"Nearby parking options available, including Tower Bridge Parking and Minories Car Park.\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Venue Coordinator] Task output: {\n",
            "  \"name\": \"Tobacco Dock\",\n",
            "  \"address\": \"Tobacco Quay, Wapping Lane, London, E1W 2SF\",\n",
            "  \"capacity\": 10000,\n",
            "  \"booking_status\": \"Available for booking\",\n",
            "  \"event_schedule\": \"09:00 - 17:00\",\n",
            "  \"transport_options\": [\n",
            "    \"Shadwell Station (5 mins walk)\",\n",
            "    \"Wapping Station (6 mins walk)\",\n",
            "    \"DLR: Tower Hill Station (15 mins), Bank DLR Station (1 stop)\",\n",
            "    \"Overground: Canary Wharf DLR (15 mins), Shoreditch Overground (2 stops)\",\n",
            "    \"London City Airport (5.4 miles)\",\n",
            "    \"Heathrow Airport: Elizabeth Line to Whitechapel Station\",\n",
            "    \"Bus 100: Direct bus service to Tobacco Dock\",\n",
            "    \"Bus D3: Direct bus service to Tobacco Dock\",\n",
            "    \"Nearby parking options available, including Tower Bridge Parking and Minories Car Park.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Logistics Manager\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Review the selected venue details. The venue coordinator may mark booking_status as 'To be confirmed'. It is your responsibility to confirm venue booking availability for the date 2025-12-15.\n",
            "\n",
            "After confirming, update the booking status to 'Confirmed'.\n",
            "Then coordinate catering and equipment for 1500 participants.\n",
            "Provide a detailed logistics confirmation summary including:\n",
            "- venue booking confirmation,\n",
            "- catering vendor,\n",
            "- equipment setup plan,\n",
            "- timing and delivery schedule.\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Logistics Manager] Task output: {\n",
            "  \"name\": \"Tobacco Dock\",\n",
            "  \"address\": \"Tobacco Quay, Wapping Lane, London, E1W 2SF\",\n",
            "  \"capacity\": 10000,\n",
            "  \"booking_status\": \"Available for booking\",\n",
            "  \"event_schedule\": \"09:00 - 17:00\",\n",
            "  \"transport_options\": [\n",
            "    \"Shadwell Station (5 mins walk)\",\n",
            "    \"Wapping Station (6 mins walk)\",\n",
            "    \"DLR: Tower Hill Station (15 mins), Bank DLR Station (1 stop)\",\n",
            "    \"Overground: Canary Wharf DLR (15 mins), Shoreditch Overground (2 stops)\",\n",
            "    \"London City Airport (5.4 miles)\",\n",
            "    \"Heathrow Airport: Elizabeth Line to Whitechapel Station\",\n",
            "    \"Bus 100: Direct bus service to Tobacco Dock\",\n",
            "    \"Bus D3: Direct bus service to Tobacco Dock\",\n",
            "    \"Nearby parking options available, including Tower Bridge Parking and Minories Car Park.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Marketing and Communications Agent\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Promote the event Global AI Leaders Summit 2025 in UK based on the confirmed venue details and logistics plan. Ensure that you read the final venue information including:\n",
            "- venue name,\n",
            "- address,\n",
            "- event schedule,\n",
            "- transport options,\n",
            "- confirmed booking status.\n",
            "\n",
            "Create a promotional plan targeting at least 1500 potential attendees. Include social media strategy, email outreach, and key messaging that highlights the venue and its accessibility.\u001b[00m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Marketing and Communications Agent] Task output: {\n",
            "  \"name\": \"Tobacco Dock\",\n",
            "  \"address\": \"Tobacco Quay, Wapping Lane, London, E1W 2SF\",\n",
            "  \"capacity\": 10000,\n",
            "  \"booking_status\": \"Available for booking\",\n",
            "  \"event_schedule\": \"09:00 - 17:00\",\n",
            "  \"transport_options\": [\n",
            "    \"Shadwell Station (5 mins walk)\",\n",
            "    \"Wapping Station (6 mins walk)\",\n",
            "    \"DLR: Tower Hill Station (15 mins), Bank DLR Station (1 stop)\",\n",
            "    \"Overground: Canary Wharf DLR (15 mins), Shoreditch Overground (2 stops)\",\n",
            "    \"London City Airport (5.4 miles)\",\n",
            "    \"Heathrow Airport: Elizabeth Line to Whitechapel Station\",\n",
            "    \"Bus 100: Direct bus service to Tobacco Dock\",\n",
            "    \"Bus D3: Direct bus service to Tobacco Dock\",\n",
            "    \"Nearby parking options available, including Tower Bridge Parking and Minories Car Park.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "with open('venue_details.json') as f:\n",
        "   data = json.load(f)\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6O0oMmjYp9H",
        "outputId": "4076c7ee-3f37-414b-cd37-088afabd6d19"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Tobacco Dock', 'address': 'Tobacco Quay, Wapping Lane, London, E1W 2SF', 'capacity': 10000, 'booking_status': 'Available for booking', 'event_schedule': '09:00 - 17:00', 'transport_options': ['Shadwell Station (5 mins walk)', 'Wapping Station (6 mins walk)', 'DLR: Tower Hill Station (15 mins), Bank DLR Station (1 stop)', 'Overground: Canary Wharf DLR (15 mins), Shoreditch Overground (2 stops)', 'London City Airport (5.4 miles)', 'Heathrow Airport: Elizabeth Line to Whitechapel Station', 'Bus 100: Direct bus service to Tobacco Dock', 'Bus D3: Direct bus service to Tobacco Dock', 'Nearby parking options available, including Tower Bridge Parking and Minories Car Park.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the final result as Markdown."
      ],
      "metadata": {
        "id": "-CT6WoKkD8Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "Mj0Gxrx3B_90",
        "outputId": "b20d8b97-d6bb-47ba-cc19-1d049882a7a5"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "{\n  \"name\": \"Tobacco Dock\",\n  \"address\": \"Tobacco Quay, Wapping Lane, London, E1W 2SF\",\n  \"capacity\": 10000,\n  \"booking_status\": \"Available for booking\",\n  \"event_schedule\": \"09:00 - 17:00\",\n  \"transport_options\": [\n    \"Shadwell Station (5 mins walk)\",\n    \"Wapping Station (6 mins walk)\",\n    \"DLR: Tower Hill Station (15 mins), Bank DLR Station (1 stop)\",\n    \"Overground: Canary Wharf DLR (15 mins), Shoreditch Overground (2 stops)\",\n    \"London City Airport (5.4 miles)\",\n    \"Heathrow Airport: Elizabeth Line to Whitechapel Station\",\n    \"Bus 100: Direct bus service to Tobacco Dock\",\n    \"Bus D3: Direct bus service to Tobacco Dock\",\n    \"Nearby parking options available, including Tower Bridge Parking and Minories Car Park.\"\n  ]\n}"
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8mzcqOu2kwSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}